{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio P&D (Machine Learning) Intelivix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em processamento e entendimento de linguagem natural, a análise de sentimento é uma das áreas que mais têm recebido atenção da comunidade científica. Os seus desafios encontram-se principalmente na identificação e tratamento adequado de sarcasmo, negação, ambiguidade linguística, etc. Este desafio consiste em classificar os trechos de textos opinativos sobre filmes presentes na base fornecida em 5 níveis de sentimento: negativo, um pouco negativo, neutro, um pouco positivo e positivo.\n",
    "\n",
    "Sobre a entrega:\n",
    "\n",
    "1. Deve-se escolher 3 diferentes algoritmos de classificação ou regressão. Deve-se utilizar apenas o arquivo `train.tsv` para criar as bases de treino, validação e teste, comparando os algoritmos com a base de teste e escolhendo o melhor, justificando a escolha.\n",
    "\n",
    "2. Os códigos e o relatório devem ser entregues em um ipython notebook didático, o qual deve ser auto-suficiente para ser executado (assumindo que o computador a executar possua todas as ferramentas necessárias instaladas).\n",
    "\n",
    "3. O relatório deve conter todas as tentativas para resolver o problema, como se estivesse contando a história da estrada percorrida para se chegar no resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para dar início à resolução deste desafio, seguem os _imports_ de todos os recursos que serão utilizados, dentre eles a biblioteca **`pandas`** para manipulação dos dados e a **`scikit-learn`** para o uso de algoritmos de aprendizagem e avaliação dos resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coleta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados foram fornecidos previamente e os que serão utilizados estão dispostos no arquivo `train.tsv`. Serão lidos e armazenados na variável `data` para que possam ser pré-processados. A base de dados é composta de 4 colunas, são elas: \n",
    "\n",
    "- **Id**: identificador único de cada registro (linha) do conjunto de dados.\n",
    "- **IdSentenca**: id de cada opinião sobre filmes. Vários registros podem ter o mesmo `IdSentenca`, pois os textos opinativos são \"quebrados\" em partes menores, formando novos registros.\n",
    "- **Texto**: o conteúdo do texto em si.\n",
    "- **Sentimento**: a classificação do sentimento relacionado àquele texto, podendo assumir os valores 0 (negativo), 1 (pouco negativo), 2 (neutro), 3 (pouco positivo) ou 4 (positivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  IdSentenca                                              Texto  \\\n",
       "0   1           1  A series of escapades demonstrating the adage ...   \n",
       "1   2           1  A series of escapades demonstrating the adage ...   \n",
       "2   3           1                                           A series   \n",
       "3   4           1                                                  A   \n",
       "4   5           1                                             series   \n",
       "\n",
       "   Sentimento  \n",
       "0           1  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dados/train.tsv\", sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se notar abaixo que o conjunto de dados possui grande quantidade de registros, também possui grande quantidade de ruído visto que as sentenças são quebradas em partes menores até chegar em uma única palavra. Supondo que não seja possível inferir sentimento para algumas palavras soltas e sem contexto, nota-se alguma forma de inconsistência na base dados. Vejamos as informações abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset contém 156060 registros, dentre os quais:\n",
      "- 7072 são opiniões negativas\n",
      "- 27273 são opiniões pouco negativas\n",
      "- 79582 são opiniões neutras\n",
      "- 32927 são opiniões pouco positivas\n",
      "- 9206 são opiniões positivas\n"
     ]
    }
   ],
   "source": [
    "print('O dataset contém {} registros, dentre os quais:'.format(data.shape[0]))\n",
    "\n",
    "print('- {} são opiniões negativas'.format(data['Sentimento'].value_counts()[0]))\n",
    "print('- {} são opiniões pouco negativas'.format(data['Sentimento'].value_counts()[1]))\n",
    "print('- {} são opiniões neutras'.format(data['Sentimento'].value_counts()[2]))\n",
    "print('- {} são opiniões pouco positivas'.format(data['Sentimento'].value_counts()[3]))\n",
    "print('- {} são opiniões positivas'.format(data['Sentimento'].value_counts()[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dito isto, faz-se necessário pensar em uma forma de limpar este _dataset_, de maneira a eliminar os dados ruidosos e manter as informações relevantes para o desenvolvimento da solução do problema. Então, surgiu a ideia de manter no _dataset_ apenas a sentença principal, mas não utilizar a classificação de sentimento atribuído a ela a priori, e sim obter e arrendodar a média da classificação de todas as sentenças que são partes dela, como pode ser visto a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "sentiments = []\n",
    "sentences_id = []\n",
    "\n",
    "for sentence_id in data['IdSentenca'].unique():\n",
    "    for index, row in data[data['IdSentenca'] == sentence_id].iterrows():\n",
    "        sentences_id.append(row['IdSentenca'])\n",
    "        texts.append(row['Texto'])\n",
    "        sentiments.append(data[data['IdSentenca'] == sentence_id]['Sentimento'].mean())\n",
    "        break\n",
    "\n",
    "new_data = pd.DataFrame(data={'IdSentenca': sentences_id, 'Texto': texts, 'Sentimento': sentiments})\n",
    "new_data['Sentimento'] = new_data['Sentimento'].apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode ser vista abaixo a nova configuração dos registros e classes da base de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset agora contém 8529 registros, dentre os quais:\n",
      "- 92 são opiniões negativas\n",
      "- 1329 são opiniões pouco negativas\n",
      "- 5078 são opiniões neutras\n",
      "- 1877 são opiniões pouco positivas\n",
      "- 153 são opiniões positivas\n"
     ]
    }
   ],
   "source": [
    "print('O dataset agora contém {} registros, dentre os quais:'.format(new_data.shape[0]))\n",
    "\n",
    "print('- {} são opiniões negativas'.format(new_data['Sentimento'].value_counts()[0]))\n",
    "print('- {} são opiniões pouco negativas'.format(new_data['Sentimento'].value_counts()[1]))\n",
    "print('- {} são opiniões neutras'.format(new_data['Sentimento'].value_counts()[2]))\n",
    "print('- {} são opiniões pouco positivas'.format(new_data['Sentimento'].value_counts()[3]))\n",
    "print('- {} são opiniões positivas'.format(new_data['Sentimento'].value_counts()[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem-se agora um conjunto de dados mais enxuto, porém ainda contendo as informações relevantes. O próximo passo é manipulá-lo de forma que seja possível aplicar corretamente os algoritmos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: a fim de otimizar a remoção de ruídos da base de dados e os resultados de classificação, surgiu a ideia de incluir um método na etapa de pré-processamento para remover as `stopwords` dos textos opinativos, utilizando a `Natural Language Toolkit (NLTK)`, biblioteca Python. `Stopwords` são palavras consideradas \"irrelevantes\" em algum contexto de alguma linguagem (nesse caso, no inglês), como por exemplo: _does_, _are_, _not_ etc. A `NLTK` provê diversas `stopwords` que remetem a alguma ação negativa e, por esse motivo, a ideia de removê-las da base de dados caiu por terra, pois no contexto de análise de sentimentos é importante avaliar proposições negativas.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, antes de utilizar algoritmos de aprendizagem, é preciso criar um _vectorizer_ que será responsável por transformar o texto bruto em notação de __[<font color='blue'>bag-of-words</font>](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)__ (saco de palavras) e/ou __[<font color='blue'>tf-idf</font>](http://www.tfidf.com/)__ (_term frequency – inverse document frequency_ ou, em português, frequência do termo – inverso da frequência nos documentos) para que, dessa forma, possam ser aplicados classificadores. Neste caso, serão testados dois _vectorizers_ (__[<font color='blue'>CountVectorizer</font>](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)__ e __[<font color='blue'>TfidfVectorizer</font>](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)__), ambos transformam o texto bruto na notação `bag-of-words`, porém o segundo usa a `bag-of-words` para colocar o texto em sua representação `tf-idf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [CountVectorizer, TfidfVectorizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isto, foram escolhidos para serem testados 3 algoritmos de aprendizagem: __[<font color='blue'>Naïve Bayes</font>](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)__, __[<font color='blue'>Regressão Logística</font>](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__ e __[<font color='blue'>Random Forest</font>](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_models = [MultinomialNB, RandomForestClassifier, LogisticRegression]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão feitas iterações entre estes vetorizadores e algoritmos de aprendizagem a fim de comparar o resultado final (acurácia) e obter a melhor combinação de ambos. Para isto, o conjunto de dados será dividido em 70% para treino e 30% para teste dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.60067001675041876: [<class 'sklearn.feature_extraction.text.TfidfVectorizer'>,\n",
      "                       <class 'sklearn.naive_bayes.MultinomialNB'>],\n",
      " 0.60837520938023448: [<class 'sklearn.feature_extraction.text.TfidfVectorizer'>,\n",
      "                       <class 'sklearn.ensemble.forest.RandomForestClassifier'>],\n",
      " 0.61122278056951429: [<class 'sklearn.feature_extraction.text.CountVectorizer'>,\n",
      "                       <class 'sklearn.ensemble.forest.RandomForestClassifier'>],\n",
      " 0.6194304857621441: [<class 'sklearn.feature_extraction.text.CountVectorizer'>,\n",
      "                      <class 'sklearn.naive_bayes.MultinomialNB'>],\n",
      " 0.63249581239530983: [<class 'sklearn.feature_extraction.text.TfidfVectorizer'>,\n",
      "                       <class 'sklearn.linear_model.logistic.LogisticRegression'>],\n",
      " 0.64857621440536017: [<class 'sklearn.feature_extraction.text.CountVectorizer'>,\n",
      "                       <class 'sklearn.linear_model.logistic.LogisticRegression'>]}\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "\n",
    "# dividir conjuntos de treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data['Texto'], \n",
    "                                                    new_data['Sentimento'], \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=101)\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    vect = vectorizer(analyzer='word')\n",
    "    train_txt = vect.fit_transform(X_train)\n",
    "    test_txt = vect.transform(X_test)\n",
    "    for learning_model in learning_models:\n",
    "        model = learning_model()\n",
    "        model.fit(train_txt, y_train)\n",
    "        model.predict(test_txt)\n",
    "        results = cross_val_predict(model, train_txt, y_train, cv=10)\n",
    "        accuracy_dict[accuracy_score(y_train, results)] = [vectorizer, learning_model]\n",
    "\n",
    "# acurácias obtidas para cada combinação vetorizador x classificador\n",
    "import pprint\n",
    "pprint.pprint(accuracy_dict) # pretty print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.feature_extraction.text.CountVectorizer,\n",
       " sklearn.linear_model.logistic.LogisticRegression]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtendo a melhor combinação vetorizador x classificador\n",
    "accuracy_dict[sorted(accuracy_dict.keys(), reverse=True)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser visto acima, a melhor combinação Vetorizador x Classificador é aplicar o `CountVectorizer` em conjunto com o modelo de Regressão Logística. Então, o fluxo será executado mais uma vez, a fim de que os resultados possam ser melhor analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_data['Texto'], \n",
    "                                                    new_data['Sentimento'], \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=101)\n",
    "\n",
    "model = LogisticRegression()\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "\n",
    "train_texts = vectorizer.fit_transform(X_train)\n",
    "model.fit(train_texts, y_train)\n",
    "test_texts = vectorizer.transform(X_test)\n",
    "model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após executar novamente o modelo de aprendizagem, os resultados serão analisados utilizando a técnica de _k-Fold Cross Validation_ (com `k=10`). Desta forma, foram calculadas as seguintes métricas: acurácia e matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo tem uma acurácia de 64.858%\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_predict(model, train_texts, y_train, cv=10) # 10-fold cross validation\n",
    "accuracy = accuracy_score(y_train, results)\n",
    "\n",
    "print('O modelo tem uma acurácia de {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito  0    1     2     3  4   All\n",
      "Real                                \n",
      "0        0   31    36     2  0    69\n",
      "1        1  253   643    22  0   919\n",
      "2        0  189  3039   339  1  3568\n",
      "3        0    9   719   576  3  1307\n",
      "4        0    1    33    69  4   107\n",
      "All      1  483  4470  1008  8  5970\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_train, results, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, como já foi concluído há alguns passos atrás, o algoritmo de aprendizagem que obteve melhor acurácia foi a Regressão Logística. No entanto, a acurácia dos outros dois algoritmos testados também foi relativamente alta, ficando abaixo da Regressão Logística por apenas 1 a 4%. Além disso, nota-se que na matriz de confusão acima, a maior quantidade de números (predições) encontra-se mais no centro e na diagonal principal da matriz. Isto pode ser visto como positivo, pois mostra que, quanddo há erros de predição, não são erros \"gritantes\" e sim erros leves, como por exemplo: confundir opinião pouco negativa ou pouco positiva com neutra e vice-versa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
